---
title: "Process data for meta analyses of the IRAP's reliability"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)
```

```{r}

# set seed for computational reproducibility
set.seed(42)

# dependencies
library(tidyverse)
library(metafor)
library(knitr)
library(kableExtra)
library(psych)

# function to round all numeric vars in a data frame
round_df <- function(df, n_digits = 3) {
  df %>% mutate_if(is.numeric, round, digits = n_digits)
}

probability_of_superiority_function <- function(x, y) {
  nx <- length(x)
  ny <- length(y)
  rx <- sum(rank(c(x, y))[1:nx])
  A = (rx / nx - (nx + 1) / 2) / ny
  return(A)
}

spearman_brown_correction <- function(r_pearson) {
  inversion <- ifelse(r_pearson < 0, -1, 1)
  val <- round(2*abs(r_pearson)/(1 + abs(r_pearson)), 2)
  return(val*inversion)
}

apa_p_value <- function(p){
  p_formatted <- ifelse(p >= 0.001, paste("=", round(p, 3)),
                        ifelse(p < 0.001, "< .001", NA))
  p_formatted <- gsub(pattern = "0.", replacement = ".", x = p_formatted, fixed = TRUE)
  p_formatted
}

add_heterogeneity_metrics_to_forest <- function(fit) {
  ## more detailed
  # bquote(paste("RE Model (Q(df = ", .(formatC(fit$k - 1)), ") = ", 
  #              .(formatC(round(fit$QE, 2))), 
  #              ", p ", .(formatC(apa_p_value(fit$QEp))),
  #              ", ", tau^2, " = ", .(formatC(round(fit$tau2, 1))), 
  #              ", ", I^2, " = ", .(formatC(round(fit$I2, 1))),
  #              "%, ", H^2," = ", .(formatC(round(fit$H2, 1))), ")"))
  ## less detailed
  bquote(paste("RE Model (", tau^2, " = ", .(formatC(round(fit$tau2, 1))), 
               ", ", I^2, " = ", .(formatC(round(fit$I2, 1))),
               "%, ", H^2," = ", .(formatC(round(fit$H2, 1))), ")"))
}

# table format in output
options(knitr.table.format = "html") 

# create directory needed to save output
dir.create("permutations")

```

# Data 

and exclusion of outliers on the basis of median mean_rt +/- 2MAD

```{r}

data_cleaned_trt <- read.csv("../trial level data/data_testretest_cleaned_trial_level.csv") 

temp <- data_cleaned_trt %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  select(unique_id, mean_rt) %>%
  mutate(median_mean_rt = median(mean_rt, na.rm = TRUE),
         mad_mean_rt = mad(mean_rt, na.rm = TRUE)) %>%
  round_df(0) %>%
  # exclude median +- 2MAD
  mutate(rt_outlier = ifelse(mean_rt < median_mean_rt-mad_mean_rt*2 |
                            mean_rt > median_mean_rt+mad_mean_rt*2, TRUE, FALSE)) %>%
  filter(rt_outlier == FALSE) %>%
  select(unique_id, rt_outlier)

data_cleaned_trt_outliers <- data_cleaned_trt %>%
  full_join(temp, by = "unique_id") %>%
  mutate(rt_outlier = ifelse(is.na(rt_outlier), TRUE, rt_outlier))

data_cleaned_trt_outliers_removed <- data_cleaned_trt_outliers %>%
  filter(rt_outlier == FALSE)


# median_est <- data_cleaned_trt_outliers %>%
#   distinct(median_mean_rt) %>%
#   pull(median_mean_rt)
# 
# mad_est <- data_cleaned_trt_outliers %>%
#   distinct(mad_mean_rt) %>%
#   pull(mad_mean_rt)
# 
# data_cleaned_trt %>%
#   distinct(unique_id, .keep_all = TRUE) %>%
#   select(unique_id, mean_rt) %>%
#   ggplot(aes(mean_rt)) +
#   geom_density() +
#   geom_vline(aes(xintercept = median_est)) +
#   geom_vline(aes(xintercept = median_est + mad_est*2)) +
#   geom_vline(aes(xintercept = median_est - mad_est*2))


data_cleaned_ic <- read.csv("../trial level data/data_internalconsistency_cleaned_trial_level.csv") 

temp2 <- data_cleaned_ic %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  select(unique_id, mean_rt) %>%
  mutate(median_mean_rt = median(mean_rt, na.rm = TRUE),
         mad_mean_rt = mad(mean_rt, na.rm = TRUE)) %>%
  round_df(0) %>%
  # exclude median +- 2MAD
  mutate(rt_outlier = ifelse(mean_rt < median_mean_rt-mad_mean_rt*2 |
                            mean_rt > median_mean_rt+mad_mean_rt*2, TRUE, FALSE)) %>%
  filter(rt_outlier == FALSE) %>%
  select(unique_id, rt_outlier)

data_cleaned_ic_outliers <- data_cleaned_ic %>%
  full_join(temp2, by = "unique_id") %>%
  mutate(rt_outlier = ifelse(is.na(rt_outlier), TRUE, rt_outlier))

data_cleaned_ic_outliers_removed <- data_cleaned_ic_outliers %>%
  filter(rt_outlier == FALSE)


# median_est <- data_cleaned_ic_outliers %>%
#   distinct(median_mean_rt) %>%
#   pull(median_mean_rt)
# 
# mad_est <- data_cleaned_ic_outliers %>%
#   distinct(mad_mean_rt) %>%
#   pull(mad_mean_rt)
# 
# data_cleaned_trt %>%
#   distinct(unique_id, .keep_all = TRUE) %>%
#   select(unique_id, mean_rt) %>%
#   ggplot(aes(mean_rt)) +
#   geom_density() +
#   geom_vline(aes(xintercept = median_est)) +
#   geom_vline(aes(xintercept = median_est + mad_est*2)) +
#   geom_vline(aes(xintercept = median_est - mad_est*2))

```

# Demographics & sample sizes

whole sample

```{r}

# write demographics to disk
data_demographics <- data_cleaned_ic_outliers %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  select(unique_id, age, gender, rt_outlier)

write_csv(data_demographics, "data_demographics.csv")


# print sample sizes
data_cleaned_ic_outliers %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  count(rt_outlier) %>%
  rename(n_outlier_exclusions = n) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_cleaned_ic_outliers_removed %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  count(domain) %>%
  rename(n_ic_after_exlucions = n) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_cleaned_trt_outliers %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  count(rt_outlier) %>%
  rename(n_trt_after_exlucions = n) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_cleaned_trt_outliers_removed %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  filter(rt_outlier == FALSE) %>%
  count(domain) %>%
  rename(n_trt_after_exlucions = n) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Test-retest reliability

## Calculate *D* scores

```{r}

data_D_scores_trt <- data_cleaned_trt_outliers_removed %>%
  filter(rt <= 10000) %>%
  group_by(unique_id, timepoint) %>%
  summarize(mean_con = mean(rt[block_type == "con"], na.rm = TRUE),
            mean_incon = mean(rt[block_type == "incon"], na.rm = TRUE),
            sd = mean(rt, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(D = (mean_incon - mean_con)/sd) %>%
  select(unique_id, D, timepoint) %>%
  spread(timepoint, D) %>%
  left_join(select(distinct(data_cleaned_trt_outliers_removed, unique_id, .keep_all = TRUE), unique_id, domain), by = "unique_id")

```

```{r fig.height=7, fig.width=7}

ggplot(data_D_scores_trt, aes(baseline, followup)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~domain)

```

## Calculate effect sizes

```{r}

calculate_icc <- function(data) {
  fit <- data %>%
    select(baseline, followup) %>%
    ICC(lmer = TRUE)

  results <- fit$results %>%
    filter(type == "ICC2") %>%
    select(type, ICC, ICC_ci_lower = "lower bound", ICC_ci_upper = "upper bound") %>%
    mutate(se = (ICC_ci_upper - ICC_ci_lower)/(1.96*2))
  
  return(results)
}

data_test_retest_icc <- data_D_scores_trt %>%
  group_by(domain) %>%
  do(calculate_icc(.)) %>%
  ungroup() %>%
  left_join(data_D_scores_trt %>%
              count(domain), by = "domain")

# data_D_scores_trt %>%
#   group_by(domain) %>%
#   summarize(cor = cor(baseline, followup))

write_csv(data_test_retest_icc, "data_test_retest_icc.csv")

```

Variance associated with each effect size calculated mathematically using the effect size and sample size.

# Internal consistency

Three methods of calculating internal consistency for the Implicit Relational Assessment Procedure (IRAP): 
- Odd vs even trials (mostly commonly reported in literature)
- First vs second half of task (more common for the most popular implicit measure, the IAT; would allow a like-for-like comparison)
- Cronbach's alpha via permutation (most robust)

## Split-half reliability via odd vs. even trials

### Calculate D scores

```{r}

data_D_scores_ic_oddeventrials <- data_cleaned_ic_outliers_removed %>%
  filter(rt <= 10000) %>%
  group_by(unique_id, trial_odd_even) %>%
  summarize(mean_con = mean(rt[block_type == "con"], na.rm = TRUE),
            mean_incon = mean(rt[block_type == "incon"], na.rm = TRUE),
            sd = mean(rt, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(D = (mean_incon - mean_con)/sd) %>%
  select(unique_id, D, trial_odd_even) %>%
  spread(trial_odd_even, D) %>%
  left_join(select(distinct(data_cleaned_ic_outliers_removed, unique_id, .keep_all = TRUE), unique_id, domain), by = "unique_id")

```

### Calculate effect sizes

Bonett transformations 

```{r}

# calculate internal consistencies
data_internal_consistency_oddeventrials <- data_D_scores_ic_oddeventrials %>%
  dplyr::select(domain, D_odd, D_even) %>%
  na.omit() %>%
  group_by(domain) %>%
  summarize(r_pearson = cor(D_odd, D_even),
            n = n()) %>%
  ungroup() %>%
  mutate(r_sb = spearman_brown_correction(r_pearson),
         parts = 2) %>%
  escalc(measure = "ABT", 
         ai = r_sb, 
         mi = parts, 
         ni = n,
         data = .) 

write_csv(data_internal_consistency_oddeventrials, "data_internal_consistency_oddeventrials.csv")

```

## Split-half reliability via first vs. second half of the task

### Calculate D scores

```{r}

data_n_trials_halves <- data_cleaned_ic_outliers_removed %>%
  group_by(unique_id) %>%
  summarize(total_n_trials = n()) 

data_halves <- data_cleaned_ic_outliers_removed %>%
  left_join(data_n_trials_halves, by = "unique_id") %>%
  group_by(unique_id) %>%
  mutate(trial_n = row_number(),
         half = ifelse(trial_n > (total_n_trials/2), "second", "first")) %>%
  ungroup()

data_D_scores_ic_firstsecond <- data_halves %>%
  filter(rt <= 10000) %>%
  group_by(unique_id, half) %>%
  summarize(mean_con = mean(rt[block_type == "con"], na.rm = TRUE),
            mean_incon = mean(rt[block_type == "incon"], na.rm = TRUE),
            sd = mean(rt, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(D = (mean_incon - mean_con)/sd) %>%
  select(unique_id, D, half) %>%
  spread(half, D) %>%
  rename(D_first = first, 
         D_second = second) %>%
  left_join(select(distinct(data_cleaned_ic_outliers_removed, unique_id, .keep_all = TRUE), unique_id, domain), by = "unique_id")

```

### Calculate effect sizes

Bonett transformations 

```{r}

# calculate internal consistencies
data_internal_consistency_firstsecondhalves <- data_D_scores_ic_firstsecond %>%
  dplyr::select(domain, D_first, D_second) %>%
  na.omit() %>%
  group_by(domain) %>%
  summarize(r_pearson = cor(D_first, D_second),
            n = n()) %>%
  ungroup() %>%
  mutate(r_sb = spearman_brown_correction(r_pearson),
         parts = 2) %>%
  escalc(measure = "ABT", 
         ai = r_sb, 
         mi = parts, 
         ni = n,
         data = .) 

write_csv(data_internal_consistency_firstsecondhalves, "data_internal_consistency_firstsecondhalves.csv")

```

## Permutation-based split half correlations 

ie an estimate of alpha through large number number of random half splits (see Parsons, Kruijt, & Fox. 2019).

Circa 25 minute runtime

### Calculate D scores

Because of the large number of D scores that are calculated (i.e., 2 per participant \* N participants \* N permutations = several million D scores) this section can take a few minutes to run. I've already done some timing optimization to speed up this process by a factor of 5, but perhaps more is possible.

```{r}

# slow runtime - circa 15 minutes, so check if there's saved results already first
if (file.exists("permutations/data_internal_consistency_permutations.RData")) {
  
  load("permutations/data_internal_consistency_permutations.RData")
  
} else {
  
  # n iterations
  n_iterations <- 2000
  
  # find domain for each id - to be joined into df further below
  data_domain_for_each_id <- data_cleaned_ic_outliers_removed %>%
    distinct(unique_id, .keep_all = TRUE) %>%
    select(unique_id, domain)
  
  # create a temp list
  data_internal_consistency_list = list()
  
  # define progress bar
  step_i <- 0
  pb = txtProgressBar(min = 0, max = n_iterations, initial = 0)
  
  # assign row ids
  data_cleaned_ic_outliers_removed_rownumbers <- data_cleaned_ic_outliers_removed %>%
    arrange(unique_id, block_type) %>%
    rownames_to_column(var = "row_id") %>%
    group_by(unique_id, block_type) %>%
    mutate(trial_number = row_number()) %>%
    ungroup()
  
  # apply workflow and append results to list
  for(i in 1:n_iterations){
    
    # sample exactly half of the data and label as subset 'a' vs 'b'
    max_trials_per_block <- data_cleaned_ic_outliers_removed_rownumbers %>%
      summarize(max_trials_per_block = max(trial_number)) %>%
      pull(max_trials_per_block)
    
    trial_subset_a <- data.frame(trial_number = seq(from = 1, to = max_trials_per_block, by = 1)) %>% 
      sample_frac(size = 0.5) %>%
      arrange(trial_number) %>%
      pull(trial_number)
    
    data_cleaned_ic_outliers_removed_rownumbers_with_subsets <- data_cleaned_ic_outliers_removed_rownumbers %>%
      mutate(subset = ifelse(trial_number %in% trial_subset_a, "a", "b")) %>%
      arrange(unique_id, block_type, trial_number)
    
    # calculate a metric of how ordered this randomized subset of the trials are
    ## start by creating the 'b' vector
    temp <- seq(from = 1, to = max_trials_per_block, by = 1)
    trial_subset_b <- temp[!temp %in% trial_subset_a]
    
    ## probability that b > a
    probability_of_superiority <- probability_of_superiority_function(trial_subset_b, trial_subset_a)
    
    subset_orderedness <- abs(probability_of_superiority - 0.50) + 0.5
    
    # then calculate D1 scores (Greenwald, Banaji & Nosek, 2003)
    # these involve: 1) trimming RTs > 10000 ms, 2) finding a mean rt for each block type, 3) findings an sd for all the pooled RTs across blocks, 4) D = (mean_incon - mean_con)/sd
    data_temp_1 <- data_cleaned_ic_outliers_removed_rownumbers_with_subsets %>%
      filter(rt <= 10000)
    
    data_temp_2 <- data_temp_1 %>%
      group_by(unique_id, subset, block_type) %>%
      summarize(mean = mean(rt, na.rm = TRUE)) %>%
      ungroup() %>%
      spread(block_type, mean) %>%
      rename(mean_con = con,
             mean_incon = incon)
    
    data_temp_3 <- data_temp_1 %>%
      group_by(unique_id, subset) %>%
      summarize(sd = mean(rt, na.rm = TRUE)) %>%
      ungroup()
    
    data_internal_consistency <- left_join(data_temp_2, data_temp_3, by = c("unique_id", "subset")) %>%
      # finish calculating D scores for each participant and subset
      mutate(D = (mean_incon - mean_con)/sd) %>%
      select(unique_id, D, subset) %>%
      spread(subset, D) %>%
      rename(D_a = a,
             D_b = b) %>%
      # re add the study domain
      left_join(data_domain_for_each_id, by = "unique_id") %>%
      # calculate correlations between subsets
      na.omit() %>%
      group_by(domain) %>%
      summarize(r_pearson = cor(D_a, D_b)) %>%
      ungroup() %>%
      # apply spearman brown correction
      mutate(r_sb = spearman_brown_correction(r_pearson)) %>%
      # add iteration
      mutate(iteration = i,
             orderedness = subset_orderedness)
    
    data_internal_consistency_list[[i]] <- data_internal_consistency
    
    # update progress bar
    step_i = step_i + 1
    setTxtProgressBar(pb, step_i)
    
  }
  
  # flatten list and parse results
  data_internal_consistency_permutations <- dplyr::bind_rows(data_internal_consistency_list)
  
  # save
  save(data_internal_consistency_permutations, 
       file = "permutations/data_internal_consistency_permutations.RData")
  
}

```

### Calculate effect sizes

Estimate of alpha obtained via mean of the resampled Spearman-Brown corrected split half correlations, when calculating D1 scores for each half and sampling 2000 permutations.   

Bonett transformations 

NB forest plot above includes empirical CIs across the permutation resamples using the percentile method, whereas the forest plot below estimates CIs based on the variance calculated from the Fischer's r-to-z and N. 

```{r fig.height=8, fig.width=8}

data_n_per_domain <- data_cleaned_ic_outliers_removed %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  count(domain) %>%
  select(domain, n)

data_internal_consistency_permuted_estimates <- data_internal_consistency_permutations %>%
  group_by(domain) %>%
  dplyr::summarize(r_sb = mean(r_sb, na.rm = TRUE)) %>%
  left_join(data_n_per_domain, by = "domain") %>%
  mutate(parts = 2) %>%
  escalc(measure = "ABT", 
         ai = r_sb, 
         mi = parts, 
         ni = n,
         data = .)

write_csv(data_internal_consistency_permuted_estimates, "data_internal_consistency_permuted_estimates.csv")

```

