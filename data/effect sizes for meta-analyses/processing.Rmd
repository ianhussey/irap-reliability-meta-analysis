---
title: "Process data for meta analyses of the IRAP's reliability"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)
```

```{r}

# dependencies
library(tidyverse)
library(metafor)
library(knitr)
library(kableExtra)
library(psych)

# function to round all numeric vars in a data frame
round_df <- function(df, n_digits = 3) {
  df %>% mutate_if(is.numeric, round, digits = n_digits)
}

probability_of_superiority_function <- function(x, y) {
  nx <- length(x)
  ny <- length(y)
  rx <- sum(rank(c(x, y))[1:nx])
  A = (rx / nx - (nx + 1) / 2) / ny
  return(A)
}

spearman_brown_correction <- function(r_pearson) {
  inversion <- ifelse(r_pearson < 0, -1, 1)
  val <- round(2*abs(r_pearson)/(1 + abs(r_pearson)), 2)
  return(val*inversion)
}

apa_p_value <- function(p){
  p_formatted <- ifelse(p >= 0.001, paste("=", round(p, 3)),
                        ifelse(p < 0.001, "< .001", NA))
  p_formatted <- gsub(pattern = "0.", replacement = ".", x = p_formatted, fixed = TRUE)
  p_formatted
}

add_heterogeneity_metrics_to_forest <- function(fit) {
  ## more detailed
  # bquote(paste("RE Model (Q(df = ", .(formatC(fit$k - 1)), ") = ", 
  #              .(formatC(round(fit$QE, 2))), 
  #              ", p ", .(formatC(apa_p_value(fit$QEp))),
  #              ", ", tau^2, " = ", .(formatC(round(fit$tau2, 1))), 
  #              ", ", I^2, " = ", .(formatC(round(fit$I2, 1))),
  #              "%, ", H^2," = ", .(formatC(round(fit$H2, 1))), ")"))
  ## less detailed
  bquote(paste("RE Model (", tau^2, " = ", .(formatC(round(fit$tau2, 1))), 
               ", ", I^2, " = ", .(formatC(round(fit$I2, 1))),
               "%, ", H^2," = ", .(formatC(round(fit$H2, 1))), ")"))
}

# table format in output
options(knitr.table.format = "html") 

```

# Data 

and exclusions for incorrect number of trials

```{r}

# INTERNAL CONSISTENCY

# Two different data sources (datasets that were had their initial cleaning and organizing done at different times): do final cleaning on these and add them together.

# get data from evaluative IRAPs
data_input_evaluative <- 
  read.csv("../evaluative IRAPs/processed/combined_latency_data.csv") %>%
  mutate(trial_odd_even = ifelse(row_number() %% 2 == 1, "D_odd", "D_even")) %>%
  # tidy domain
  rename(domain = experiment) %>%
  mutate(domain = dplyr::recode(domain,
                                `chad bodyimage` = "Body shape evaluations",
                                `chad friendenemy` = "Friend-Enemy evaluations",
                                `chad gender` = "Gender stereotypes",
                                `chad lincolnhitler` = "Lincoln-Hitler evaluations",
                                `chad race`	 = "Racial evaluations 2",
                                `chad religion` = "Christianity-Islam",
                                `ian death emma` = "Life/Death evaluations 1",
                                `ian death june` = "Life/Death evaluations 2",
                                `ian death tarah` = "Life/Death evaluations 3",
                                `ian race dearbhail` = "Racial evaluations 1",
                                `ian race katie` = "Racial evaluations 1")) %>%
  arrange(as.character(domain))

# do exclusions for unique ids with wrong number of trials
data_participants_with_correct_n_trials <- data_input_evaluative %>%
  count(unique_id) %>%
  filter(n %in% c(144, 192)) # methodologically plausible number of trials

data_cleaned_ic_evaluative <- semi_join(data_input_evaluative, data_participants_with_correct_n_trials, by = "unique_id")



# get data from nonevaluative IRAPs
# nb exclusions for unique ids with wrong number of trials already done in processing
data_cleaned_ic_nonevaluative <- 
  read.csv("../nonevaluative IRAPs/processed/combined_latency_data.csv") %>%
  mutate(trial_odd_even = ifelse(row_number() %% 2 == 1, "D_odd", "D_even")) %>%
  # tidy domain
  rename(domain = experiment) %>%
  mutate(domain = dplyr::recode(domain,
                                `countries acknowledge 1` = "Countries - acknowledge suffering 1",
                                `countries care 1` = "Countries - care about suffering 1",
                                `countries 2 acknowledge` = "Countries - acknowledge suffering 2",
                                `countries 2 care` = "Countries - care about suffering 2",
                                `disgust` = "Digust sensitivity",
                                `positive_negative` = "Valenced categories evaluations",
                                `sexuality` = "Sexuality and arousal",
                                `food hunger` = "Food and hunger",
                                `shapes and colors YN rule` = "Shapes and colors 1",
                                `shapes and colors YN correct` = "Shapes and colors 2",
                                `shapes and colors TF correct` = "Shapes and colors 3",
                                `shapes and colors TF rule` = "Shapes and colors 4",
                                `shapes and colors exp 2 full rule` = "Shapes and colors 5",
                                `shapes and colors exp 2 minimal rule` = "Shapes and colors 6",
                                `shapes and colors exp 3` = "Shapes and colors 7")) %>%
  arrange(as.character(domain)) 

# combined
data_combined_ic <- bind_rows(data_cleaned_ic_evaluative, 
                           data_cleaned_ic_nonevaluative) %>%
  mutate(domain = as.factor(as.character(domain)))

# remove participant with the wrong number of trials/duplicate data
data_n_trials <- data_combined_ic %>%
  group_by(unique_id) %>%
  summarise(n = n()) %>%
  filter(n %in% c(144, 192, 240))

data_cleaned_ic <- data_combined_ic %>%
  semi_join(data_n_trials, by = "unique_id")



# TEST RETEST

data_cleaned_trt <- 
  read.csv("../test-retest IRAPs/processed/combined_latency_data.csv") %>%
  # tidy domain
  rename(domain = experiment) %>%
  mutate(domain = dplyr::recode(domain,
                                `disgust` = "Digust sensitivity (immediate followup)",
                                `sexuality test retest` = "Sexuality and arousal (7 day followup)")) %>%
  arrange(as.character(domain))

```

# Demographics & sample sizes

```{r}

data_demographics <- 
  bind_rows(mutate(data_cleaned_ic, type = "internal consistency"),
          mutate(data_cleaned_trt, type = "test retest")) %>%
  mutate(unique_id_and_type = paste(unique_id, type)) %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  select(unique_id_and_type, unique_id, type, age, gender)

write_csv(data_demographics, "data_demographics.csv")

```

# Test-retest reliability

## Calculate *D* scores

```{r}

data_D_scores <- data_cleaned_trt %>%
  filter(rt <= 10000) %>%
  group_by(unique_id, timepoint) %>%
  summarize(mean_con = mean(rt[block_type == "con"], na.rm = TRUE),
            mean_incon = mean(rt[block_type == "incon"], na.rm = TRUE),
            sd = mean(rt, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(D = (mean_incon - mean_con)/sd) %>%
  select(unique_id, D, timepoint) %>%
  spread(timepoint, D) %>%
  left_join(select(distinct(data_cleaned_trt, unique_id, .keep_all = TRUE), unique_id, domain), by = "unique_id")

```

## Calcualte effect sizes

```{r}

fit_digust <- data_D_scores %>%
  filter(domain == "Digust sensitivity (immediate followup)") %>%
  select(baseline, followup) %>%
  ICC(lmer = TRUE)

icc_disgust <- fit_digust$results %>%
  filter(type == "ICC2") %>%
  mutate(domain = "Digust sensitivity (immediate followup)") %>%
  select(domain, type, ICC, "lower bound", "upper bound") %>%
  mutate(se = (`upper bound` - `lower bound`)/(1.96*2))


fit_sexuality <- data_D_scores %>%
  filter(domain == "Sexuality and arousal (7 day followup)") %>%
  select(baseline, followup) %>%
  ICC(lmer = TRUE)

icc_sexuality <- fit_sexuality$results %>%
  filter(type == "ICC2") %>%
  mutate(domain = "Sexuality and arousal (7 day followup)") %>%
  select(domain, type, ICC, "lower bound", "upper bound") %>%
  mutate(se = (`upper bound` - `lower bound`)/(1.96*2))


data_test_retest_icc <- 
  bind_rows(icc_disgust,
            icc_sexuality) %>%
  round_df(2) %>%
  filter(type == "ICC2")

write_csv(data_test_retest_icc, "data_test_retest_icc.csv")

```

Variance associated with each effect size calculated mathematically using the effect size and sample size.

# Internal consistency

Three methods of calculating internal consistency for the Implicit Relational Assessment Procedure (IRAP): 
- Odd vs even trials (mostly commonly reported in literature)
- First vs second half of task (more common for the most popular implicit measure, the IAT; would allow a like-for-like comparison)
- Cronbach's alpha via permutation (most robust)

## Split-half reliability via odd vs. even trials

### Calculate D scores

```{r}

data_D_scores <- data_cleaned_ic %>%
  filter(rt <= 10000) %>%
  group_by(unique_id, trial_odd_even) %>%
  summarize(mean_con = mean(rt[block_type == "con"], na.rm = TRUE),
            mean_incon = mean(rt[block_type == "incon"], na.rm = TRUE),
            sd = mean(rt, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(D = (mean_incon - mean_con)/sd) %>%
  select(unique_id, D, trial_odd_even) %>%
  spread(trial_odd_even, D) %>%
  left_join(select(distinct(data_cleaned_ic, unique_id, .keep_all = TRUE), unique_id, domain), by = "unique_id")

```

### Calculate effect sizes

Bonett transformations 

```{r}

# calculate internal consistencies
data_internal_consistency_oddeventrials <- data_D_scores %>%
  dplyr::select(domain, D_odd, D_even) %>%
  na.omit() %>%
  group_by(domain) %>%
  summarize(r_pearson = cor(D_odd, D_even),
            n = n()) %>%
  ungroup() %>%
  mutate(r_sb = spearman_brown_correction(r_pearson),
         parts = 2) %>%
  escalc(measure = "ABT", 
         ai = r_sb, 
         mi = parts, 
         ni = n,
         data = .) 

write_csv(data_internal_consistency_oddeventrials, "data_internal_consistency_oddeventrials.csv")

```

## Split-half reliability via first vs. second half of the task

### Calculate D scores

```{r}

data_n_trials <- 
  data_cleaned_ic %>%
  group_by(unique_id) %>%
  summarize(total_n_trials = n()) 

data_halves <- data_cleaned_ic %>%
  left_join(data_n_trials, by = "unique_id") %>%
  group_by(unique_id) %>%
  mutate(trial_n = row_number(),
         half = ifelse(trial_n > (total_n_trials/2), "second", "first")) %>%
  ungroup()

data_D_scores_firstsecond <- data_halves %>%
  filter(rt <= 10000) %>%
  group_by(unique_id, half) %>%
  summarize(mean_con = mean(rt[block_type == "con"], na.rm = TRUE),
            mean_incon = mean(rt[block_type == "incon"], na.rm = TRUE),
            sd = mean(rt, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(D = (mean_incon - mean_con)/sd) %>%
  select(unique_id, D, half) %>%
  spread(half, D) %>%
  rename(D_first = first, 
         D_second = second) %>%
  left_join(select(distinct(data_cleaned_ic, unique_id, .keep_all = TRUE), unique_id, domain), by = "unique_id")

```

### Calculate effect sizes

Bonett transformations 

```{r}

# calculate internal consistencies
data_internal_consistency_firstsecondhalves <- data_D_scores_firstsecond %>%
  dplyr::select(domain, D_first, D_second) %>%
  na.omit() %>%
  group_by(domain) %>%
  summarize(r_pearson = cor(D_first, D_second),
            n = n()) %>%
  ungroup() %>%
  mutate(r_sb = spearman_brown_correction(r_pearson),
         parts = 2) %>%
  escalc(measure = "ABT", 
         ai = r_sb, 
         mi = parts, 
         ni = n,
         data = .) 

write_csv(data_internal_consistency_firstsecondhalves, "data_internal_consistency_firstsecondhalves.csv")

```

## Permutation-based split half correlations 

ie an estimate of alpha through large number number of random half splits (see Parsons, Kruijt, & Fox. 2019).

### Calculate D scores

Because of the large number of D scores that are calculated (i.e., 2 per participant \* 437 participants \* 2000 permutations = 1.75 million D scores) this section can take a few minutes to run. I've already done some timing optimization to speed up this process by a factor of 5, but perhaps more is possible.

```{r}

# slow runtime - circa 10 minutes, so check if there's saved results already first
if (file.exists("permutations/data_internal_consistency_permutations.RData")) {
  
  load("permutations/data_internal_consistency_permutations.RData")
  
} else {
  
  # n iterations
  n_iterations <- 5000
  
  # find domain for each id - to be joined into df further below
  data_domain_for_each_id <- data_cleaned_ic %>%
    distinct(unique_id, .keep_all = TRUE) %>%
    select(unique_id, domain)
  
  # create a temp list
  data_internal_consistency_list = list()
  
  # define progress bar
  step_i <- 0
  pb = txtProgressBar(min = 0, max = n_iterations, initial = 0)
  
  # assign row ids
  data_cleaned_ic_rownumbers <- data_cleaned_ic %>%
    arrange(unique_id, block_type) %>%
    rownames_to_column(var = "row_id") %>%
    group_by(unique_id, block_type) %>%
    mutate(trial_number = row_number()) %>%
    ungroup()
  
  # apply workflow and append results to list
  for(i in 1:n_iterations){
    
    # sample exactly half of the data and label as subset 'a' vs 'b'
    max_trials_per_block <- data_cleaned_ic_rownumbers %>%
      summarize(max_trials_per_block = max(trial_number)) %>%
      pull(max_trials_per_block)
    
    trial_subset_a <- data.frame(trial_number = seq(from = 1, to = max_trials_per_block, by = 1)) %>% 
      sample_frac(size = 0.5) %>%
      arrange(trial_number) %>%
      pull(trial_number)
    
    data_cleaned_ic_rownumbers_with_subsets <- data_cleaned_ic_rownumbers %>%
      mutate(subset = ifelse(trial_number %in% trial_subset_a, "a", "b")) %>%
      arrange(unique_id, block_type, trial_number)
    
    # calculate a metric of how ordered this randomized subset of the trials are
    ## start by creating the 'b' vector
    temp <- seq(from = 1, to = max_trials_per_block, by = 1)
    trial_subset_b <- temp[!temp %in% trial_subset_a]
    
    ## probability that b > a
    probability_of_superiority <- probability_of_superiority_function(trial_subset_b, trial_subset_a)
    
    subset_orderedness <- abs(probability_of_superiority - 0.50) + 0.5
    
    # then calculate D1 scores (Greenwald, Banaji & Nosek, 2003)
    # these involve: 1) trimming RTs > 10000 ms, 2) finding a mean rt for each block type, 3) findings an sd for all the pooled RTs across blocks, 4) D = (mean_incon - mean_con)/sd
    data_temp_1 <- data_cleaned_ic_rownumbers_with_subsets %>%
      filter(rt <= 10000)
    
    data_temp_2 <- data_temp_1 %>%
      group_by(unique_id, subset, block_type) %>%
      summarize(mean = mean(rt, na.rm = TRUE)) %>%
      ungroup() %>%
      spread(block_type, mean) %>%
      rename(mean_con = con,
             mean_incon = incon)
    
    data_temp_3 <- data_temp_1 %>%
      group_by(unique_id, subset) %>%
      summarize(sd = mean(rt, na.rm = TRUE)) %>%
      ungroup()
    
    data_internal_consistency <- left_join(data_temp_2, data_temp_3, by = c("unique_id", "subset")) %>%
      # finish calculating D scores for each participant and subset
      mutate(D = (mean_incon - mean_con)/sd) %>%
      select(unique_id, D, subset) %>%
      spread(subset, D) %>%
      rename(D_a = a,
             D_b = b) %>%
      # re add the study domain
      left_join(data_domain_for_each_id, by = "unique_id") %>%
      # calculate correlations between subsets
      na.omit() %>%
      group_by(domain) %>%
      summarize(r_pearson = cor(D_a, D_b)) %>%
      ungroup() %>%
      # apply spearman brown correction
      mutate(r_sb = spearman_brown_correction(r_pearson)) %>%
      # add iteration
      mutate(iteration = i,
             orderedness = subset_orderedness)
    
    data_internal_consistency_list[[i]] <- data_internal_consistency
    
    # update progress bar
    step_i = step_i + 1
    setTxtProgressBar(pb, step_i)
    
  }
  
  # flatten list and parse results
  data_internal_consistency_permutations <- dplyr::bind_rows(data_internal_consistency_list)
  
  # save
  save(data_internal_consistency_permutations, 
       file = "permutations/data_internal_consistency_permutations.RData")
  
}

```

### Calculate effect sizes

Estimate of alpha obtained via mean of the resampled Spearman-Brown corrected split half correlations, when calculating D1 scores for each half and sampling 5000 permutations.   

Bonett transformations 

NB forest plot above includes empirical CIs across the permutation resamples using the percentile method, whereas the forest plot below estimates CIs based on the variance calculated from the Fischer's r-to-z and N. 

```{r fig.height=8, fig.width=8}

data_n_per_domain <- data_cleaned_ic %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  count(domain) %>%
  select(domain, n)

data_internal_consistency_permuted_estimates <- data_internal_consistency_permutations %>%
  group_by(domain) %>%
  dplyr::summarize(r_sb = mean(r_sb, na.rm = TRUE)) %>%
  left_join(data_n_per_domain, by = "domain") %>%
  mutate(parts = 2) %>%
  escalc(measure = "ABT", 
         ai = r_sb, 
         mi = parts, 
         ni = n,
         data = .)

write_csv(data_internal_consistency_permuted_estimates, "data_internal_consistency_permuted_estimates.csv")

```

